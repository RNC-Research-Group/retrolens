{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>matched_image</th>\n",
       "      <th>Pixel_ER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Retrolens/Tasman/Motueka/Shorelines/Motueka_22SEP1969.shp</td>\n",
       "      <td>Retrolens/Tasman/Motueka/Stack/Motueka_22SEP1969_mosaic.jp2</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Retrolens/Tasman/Motueka/Shorelines/Motueka_27MAR1947.shp</td>\n",
       "      <td>Retrolens/Tasman/Motueka/Stack/Motueka_27MAR1947_mosaic.jp2</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Retrolens/Tasman/Motueka/Shorelines/Motueka_19MAY1958.shp</td>\n",
       "      <td>Retrolens/Tasman/Motueka/Stack/Motueka_19MAY1958_mosaic.jp2</td>\n",
       "      <td>1.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Retrolens/Tasman/ TorrentBay/Shorelines/TorrentBay_09APR1965.shp</td>\n",
       "      <td>Retrolens/Tasman/ TorrentBay/Stack/TorrentBay_09APR1965_mosaic.jp2</td>\n",
       "      <td>0.763318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Retrolens/Tasman/ TorrentBay/Shorelines/TorrentBay_04MAY1944.shp</td>\n",
       "      <td>Retrolens/Tasman/ TorrentBay/Stack/TorrentBay_04MAY1944_mosaic.jp2</td>\n",
       "      <td>0.743579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1329</th>\n",
       "      <td>MaxarImagery/HighFreq/WestCoast/CartersBeach/Shorelines/CartersBeach_02MAR2019.shp</td>\n",
       "      <td>MaxarImagery/HighFreq/WestCoast/CartersBeach/Imagery/Stack/CartersBeach_02MAR2019.tif</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1330</th>\n",
       "      <td>MaxarImagery/HighFreq/WestCoast/Ohinemaka/Shorelines/Ohinemaka_25MAR2010.shp</td>\n",
       "      <td>MaxarImagery/HighFreq/WestCoast/Ohinemaka/Imagery/Stack/Ohinemaka_25MAR2010.tif</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>MaxarImagery/HighFreq/WestCoast/Ohinemaka/Shorelines/Ohinemaka_08MAR2022.shp</td>\n",
       "      <td>MaxarImagery/HighFreq/WestCoast/Ohinemaka/Imagery/Stack/Ohinemaka_08MAR2022.tif</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1338</th>\n",
       "      <td>MaxarImagery/HighFreq/Wellington/KapitiMid/Shorelines/KapitiMid_19JAN2006.shp</td>\n",
       "      <td>MaxarImagery/HighFreq/Wellington/KapitiMid/Imagery/Stack/KapitiMid_19JAN2006.tif</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>MaxarImagery/HighFreq/WestCoast/Hunt Beach/Shorelines/HuntBeach_30DEC2011.shp</td>\n",
       "      <td>MaxarImagery/HighFreq/WestCoast/Hunt Beach/Imagery/Stack/HuntBeach_30DEC2011.tif</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>463 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                filename  \\\n",
       "1                              Retrolens/Tasman/Motueka/Shorelines/Motueka_22SEP1969.shp   \n",
       "2                              Retrolens/Tasman/Motueka/Shorelines/Motueka_27MAR1947.shp   \n",
       "3                              Retrolens/Tasman/Motueka/Shorelines/Motueka_19MAY1958.shp   \n",
       "4                       Retrolens/Tasman/ TorrentBay/Shorelines/TorrentBay_09APR1965.shp   \n",
       "5                       Retrolens/Tasman/ TorrentBay/Shorelines/TorrentBay_04MAY1944.shp   \n",
       "...                                                                                  ...   \n",
       "1329  MaxarImagery/HighFreq/WestCoast/CartersBeach/Shorelines/CartersBeach_02MAR2019.shp   \n",
       "1330        MaxarImagery/HighFreq/WestCoast/Ohinemaka/Shorelines/Ohinemaka_25MAR2010.shp   \n",
       "1333        MaxarImagery/HighFreq/WestCoast/Ohinemaka/Shorelines/Ohinemaka_08MAR2022.shp   \n",
       "1338       MaxarImagery/HighFreq/Wellington/KapitiMid/Shorelines/KapitiMid_19JAN2006.shp   \n",
       "1346       MaxarImagery/HighFreq/WestCoast/Hunt Beach/Shorelines/HuntBeach_30DEC2011.shp   \n",
       "\n",
       "                                                                              matched_image  \\\n",
       "1                               Retrolens/Tasman/Motueka/Stack/Motueka_22SEP1969_mosaic.jp2   \n",
       "2                               Retrolens/Tasman/Motueka/Stack/Motueka_27MAR1947_mosaic.jp2   \n",
       "3                               Retrolens/Tasman/Motueka/Stack/Motueka_19MAY1958_mosaic.jp2   \n",
       "4                        Retrolens/Tasman/ TorrentBay/Stack/TorrentBay_09APR1965_mosaic.jp2   \n",
       "5                        Retrolens/Tasman/ TorrentBay/Stack/TorrentBay_04MAY1944_mosaic.jp2   \n",
       "...                                                                                     ...   \n",
       "1329  MaxarImagery/HighFreq/WestCoast/CartersBeach/Imagery/Stack/CartersBeach_02MAR2019.tif   \n",
       "1330        MaxarImagery/HighFreq/WestCoast/Ohinemaka/Imagery/Stack/Ohinemaka_25MAR2010.tif   \n",
       "1333        MaxarImagery/HighFreq/WestCoast/Ohinemaka/Imagery/Stack/Ohinemaka_08MAR2022.tif   \n",
       "1338       MaxarImagery/HighFreq/Wellington/KapitiMid/Imagery/Stack/KapitiMid_19JAN2006.tif   \n",
       "1346       MaxarImagery/HighFreq/WestCoast/Hunt Beach/Imagery/Stack/HuntBeach_30DEC2011.tif   \n",
       "\n",
       "      Pixel_ER  \n",
       "1     0.700000  \n",
       "2     0.550000  \n",
       "3     1.250000  \n",
       "4     0.763318  \n",
       "5     0.743579  \n",
       "...        ...  \n",
       "1329  0.500000  \n",
       "1330  0.500000  \n",
       "1333  0.500000  \n",
       "1338  0.600000  \n",
       "1346  0.500000  \n",
       "\n",
       "[463 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd  # Tabular data\n",
    "from glob import glob  # File pattern matching\n",
    "import os  # Operating System\n",
    "import geopandas as gpd  # Geospatial data\n",
    "import re  # Regular expressions\n",
    "import math\n",
    "from tqdm.auto import tqdm  # Progress bars\n",
    "from tqdm.contrib.concurrent import thread_map, process_map  # Parallel operations\n",
    "import rapidfuzz # Fuzzy string matching\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_colwidth\", 130)\n",
    "df = pd.read_csv(\"meta.csv\")\n",
    "# Filter to just shapefiles that have the CRS column defined\n",
    "df = df[df[\"CPS\"]]\n",
    "df[\"Pixel_ER\"] = (\n",
    "    df.res.str.replace(\"(\", \"\", regex=False).str.split(\",\").str[0].astype(float)\n",
    ")\n",
    "df = df[[\"filename\", \"matched_image\", \"Pixel_ER\"]]\n",
    "# Testing with BigBay\n",
    "# df = df[df.filename.str.contains(\"BigBay\")]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total UNCY:  \n",
    "Total shoreline uncertainty (Et) is calculated as the root sum of squares of the pixel error (Ep), georeferencing error (Eg) and digitising error (Ed)  \n",
    "\n",
    "$E_t = \\sqrt{E_p^2 + E_g^2 + E_d^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              25/05/1944\n",
       "1              25/05/1944\n",
       "2              25/05/1944\n",
       "3              25/05/1944\n",
       "4              25/05/1944\n",
       "5              25/05/1944\n",
       "6              25/05/1944\n",
       "7              25/05/1944\n",
       "8              25/05/1944\n",
       "9              25/05/1944\n",
       "10    1973-03-12 00:00:00\n",
       "11             27/11/1994\n",
       "12             27/11/1994\n",
       "13             27/11/1994\n",
       "14             27/11/1994\n",
       "15             27/11/1994\n",
       "16             17/02/1995\n",
       "17             17/02/1995\n",
       "18             17/02/1995\n",
       "19             27/11/1994\n",
       "20             27/11/1994\n",
       "21             27/11/1994\n",
       "Name: Date, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_excel(\"ressci201900060-RNC2-Coastal/Retrolens/Manawatu/Akitio/Akitio.csv\").Date.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8653053702b34ec1926d501db05f46bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/463 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching 7/11/1952 to 17/11/1952 with score 94.73684210526316 for ressci201900060-RNC2-Coastal/Retrolens/Tasman/ TorrentBay/TorrentBay.csv\n",
      "Ambiguous scales found for ressci201900060-RNC2-Coastal/Retrolens/Tasman/RuataniwhaInlet/RuataniwhaInlet.csv for date 11/10/1950: [16700 17400]\n",
      "Matching 1980 to 30/01/1980 with score 90.0 for ressci201900060-RNC2-Coastal/Retrolens/Tasman/RuataniwhaInlet/RuataniwhaInlet.csv\n",
      "Ambiguous CSVs: ['ressci201900060-RNC2-Coastal/Retrolens/Tasman/PortPuponga/PortPuponga.csv', 'ressci201900060-RNC2-Coastal/Retrolens/Tasman/PortPuponga/PortPuponga2.csv']\n",
      "Ambiguous CSVs: ['ressci201900060-RNC2-Coastal/Retrolens/Tasman/PortPuponga/PortPuponga.csv', 'ressci201900060-RNC2-Coastal/Retrolens/Tasman/PortPuponga/PortPuponga2.csv']\n",
      "Matching 18/09/1985 to 13/09/1985 with score 90.0 for ressci201900060-RNC2-Coastal/Retrolens/Tasman/MoutereSpit/MoutereSpit.csv\n",
      "Ambiguous CSVs: ['ressci201900060-RNC2-Coastal/Retrolens/Tasman/PortPuponga/PortPuponga.csv', 'ressci201900060-RNC2-Coastal/Retrolens/Tasman/PortPuponga/PortPuponga2.csv']\n",
      "Ambiguous CSVs: ['ressci201900060-RNC2-Coastal/Retrolens/Tasman/PortPuponga/PortPuponga.csv', 'ressci201900060-RNC2-Coastal/Retrolens/Tasman/PortPuponga/PortPuponga2.csv']\n",
      "Ambiguous CSVs: ['ressci201900060-RNC2-Coastal/Retrolens/Tasman/PortPuponga/PortPuponga.csv', 'ressci201900060-RNC2-Coastal/Retrolens/Tasman/PortPuponga/PortPuponga2.csv']\n",
      "Ambiguous CSVs: ['ressci201900060-RNC2-Coastal/Retrolens/Tasman/PortPuponga/PortPuponga.csv', 'ressci201900060-RNC2-Coastal/Retrolens/Tasman/PortPuponga/PortPuponga2.csv']\n",
      "Ambiguous CSVs: ['ressci201900060-RNC2-Coastal/Retrolens/Tasman/PortPuponga/PortPuponga.csv', 'ressci201900060-RNC2-Coastal/Retrolens/Tasman/PortPuponga/PortPuponga2.csv']\n",
      "No scales found for ressci201900060-RNC2-Coastal/Retrolens/Tasman/MoutereRiver/MoutereRiver.csv for date 19/05/1958, removing RMSE filter\n",
      "Scales now: [44500]\n",
      "Matching 18/10/1985 to 18/10/1984 with score 90.0 for ressci201900060-RNC2-Coastal/Retrolens/Southland/OretiBeach_West/OretiBeach_West.csv\n",
      "ressci201900060-RNC2-Coastal/Retrolens/Manawatu/Akitio/Akitio.csv is actually an Excel file\n",
      "ressci201900060-RNC2-Coastal/Retrolens/Manawatu/Akitio/Akitio.csv is actually an Excel file\n",
      "Matching 21/10/1979 to 24/10/1979 with score 90.0 for ressci201900060-RNC2-Coastal/Retrolens/Auckland/MedlandsKaitoke/MedlandsKaitoke.csv\n",
      "Ambiguous scales found for ressci201900060-RNC2-Coastal/Retrolens/Auckland/MedlandsKaitoke/MedlandsKaitoke.csv for date 21/10/1979: [25000 15000]\n",
      "Matching 10/09/0971 to 10/9/1971 with score 84.21052631578947 for ressci201900060-RNC2-Coastal/Retrolens/Bay of Plenty/OmaioBay/OmaioBay.csv\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/nyou045/retrolens/Uncertainty.ipynb Cell 4\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B420/home/nyou045/retrolens/Uncertainty.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=70'>71</a>\u001b[0m filename \u001b[39m=\u001b[39m row\u001b[39m.\u001b[39mfilename\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B420/home/nyou045/retrolens/Uncertainty.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=71'>72</a>\u001b[0m shapefile \u001b[39m=\u001b[39m gpd\u001b[39m.\u001b[39mread_file(filename)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B420/home/nyou045/retrolens/Uncertainty.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=72'>73</a>\u001b[0m source \u001b[39m=\u001b[39m shapefile\u001b[39m.\u001b[39;49mSource\u001b[39m.\u001b[39;49munique()[\u001b[39m0\u001b[39;49m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B420/home/nyou045/retrolens/Uncertainty.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=73'>74</a>\u001b[0m \u001b[39mif\u001b[39;00m source \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mMAX\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B420/home/nyou045/retrolens/Uncertainty.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=74'>75</a>\u001b[0m     photoscale \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mVHR\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "def get_scale(filename, DSASDate):\n",
    "    # Find CSV for AOI\n",
    "    bits = filename.split(\"/\")\n",
    "    terminator = min(\n",
    "        bits.index(\"Stack\") if \"Stack\" in bits else 1024,\n",
    "        bits.index(\"Shorelines\") if \"Shorelines\" in bits else 1024,\n",
    "    )\n",
    "    bits = bits[:terminator]\n",
    "    csv_path_pattern = f\"ressci201900060-RNC2-Coastal/{'/'.join(bits)}/*.csv\"\n",
    "    csv_candidates = glob(csv_path_pattern)\n",
    "    if len(csv_candidates) == 0:\n",
    "        print(f\"No CSV found for {csv_path_pattern}\")\n",
    "    elif len(csv_candidates) > 1:\n",
    "        print(f\"Ambiguous CSVs: {csv_candidates}\")\n",
    "        csv_candidates = [csv_candidates[0]]\n",
    "    assert len(csv_candidates) == 1\n",
    "    csv_filename = csv_candidates[0]\n",
    "    try:\n",
    "        csv = pd.read_csv(csv_filename, encoding=\"cp1252\")\n",
    "    except UnicodeDecodeError:\n",
    "        # Excel file saved with .csv extension\n",
    "        print(f\"{csv_filename} is actually an Excel file\")\n",
    "        csv = pd.read_excel(csv_filename)\n",
    "        csv.Date = csv.Date.astype(str)\n",
    "    if \"RMSE\" not in csv.columns:\n",
    "        print(f\"{csv_filename} has no RMSE column\")\n",
    "    \n",
    "    year = re.search(r'(\\d{4})', filename).group(1)\n",
    "\n",
    "    # Fuzzy string match dates. Lots of typos.\n",
    "    matched_date, score, index = rapidfuzz.process.extractOne(query=DSASDate, choices=csv.Date.unique())\n",
    "    if score < 50:\n",
    "        # Terrible match score, just use year\n",
    "        matched_date, score, index = rapidfuzz.process.extractOne(query=year, choices=csv.Date.unique())\n",
    "        print(f\"Matching {year} to {matched_date} with score {score} for {csv_filename}\")\n",
    "    elif DSASDate != matched_date:\n",
    "        print(f\"Matching {DSASDate} to {matched_date} with score {score} for {csv_filename}\")\n",
    "    filtered_csv = csv[(csv.Date == matched_date) & ~csv.RMSE.isna()]\n",
    "    scales = filtered_csv.Scale.unique()\n",
    "    if len(scales) == 0:\n",
    "        print(f\"No scales found for {csv_filename} for date {DSASDate}, removing RMSE filter\")\n",
    "        filtered_csv = csv[(csv.Date.str.contains(matched_date))]\n",
    "        scales = filtered_csv.Scale.unique()\n",
    "        print(f\"Scales now: {scales}\")\n",
    "        if len(scales) == 0:\n",
    "            print(f\"Still no scales found for {csv_filename} for date {matched_date}, reducing date filter just to year from filename {year}\")\n",
    "            filtered_csv = csv[(csv.Date.str.contains(year))]\n",
    "            scales = filtered_csv.Scale.unique()\n",
    "            print(f\"Scales now: {scales}\")\n",
    "    if len(scales) > 1:\n",
    "        print(f\"Ambiguous scales found for {csv_candidates[0]} for date {DSASDate}: {scales}\")\n",
    "        scales = [scales[0]]\n",
    "    if len(scales) == 0:\n",
    "        print(f\"Can't find a scale for {filename}\")\n",
    "    assert len(scales) == 1\n",
    "    return scales[0]\n",
    "\n",
    "\n",
    "def get_Georef_ER(scale):\n",
    "    if scale < 20000:\n",
    "        return 2.09\n",
    "    elif scale < 30000:\n",
    "        return 2.43\n",
    "    else:\n",
    "        return 2.9\n",
    "\n",
    "\n",
    "CPS_error_lookup = {1: 0.43, 2: 0.73, 3: 0.97, 4: 2.07, 5: 8.59}\n",
    "\n",
    "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    filename = row.filename\n",
    "    shapefile = gpd.read_file(filename)\n",
    "    source = shapefile.Source.unique()[0]\n",
    "    if source == \"MAX\":\n",
    "        photoscale = \"VHR\"\n",
    "        Georef_ER = 1.17\n",
    "    elif source == \"LDS\":\n",
    "        photoscale = \"VHR\"\n",
    "        Georef_ER = 0\n",
    "    else:\n",
    "        DSASDate = shapefile.DSASDate.unique()[0].lstrip(\"0\")\n",
    "        photoscale = get_scale(filename, DSASDate)\n",
    "        Georef_ER = get_Georef_ER(photoscale)\n",
    "\n",
    "    # Store inputs in shapefile\n",
    "    shapefile[\"Photoscale\"] = photoscale\n",
    "    shapefile[\"Georef_ER\"] = Georef_ER\n",
    "    shapefile[\"Pixel_Er\"] = row.Pixel_ER\n",
    "\n",
    "    # Calculate Total_UNCY\n",
    "    Ep = row.Pixel_ER\n",
    "    Eg = Georef_ER\n",
    "    for i, row in shapefile.iterrows():\n",
    "        if row.CPS not in CPS_error_lookup:\n",
    "            continue\n",
    "        Ed = CPS_error_lookup[row.CPS]\n",
    "        Et = math.sqrt(Ep**2 + Eg**2 + Ed**2)\n",
    "        shapefile.loc[i, \"Total_UNCY\"] = Et\n",
    "    # display(shapefile)\n",
    "    # To write results back to file:\n",
    "    # shapefile.to_file(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
