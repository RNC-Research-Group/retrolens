{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>matched_image</th>\n",
       "      <th>Pixel_ER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Retrolens/Tasman/Motueka/Shorelines/Motueka_22SEP1969.shp</td>\n",
       "      <td>Retrolens/Tasman/Motueka/Stack/Motueka_22SEP1969_mosaic.jp2</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Retrolens/Tasman/Motueka/Shorelines/Motueka_27MAR1947.shp</td>\n",
       "      <td>Retrolens/Tasman/Motueka/Stack/Motueka_27MAR1947_mosaic.jp2</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Retrolens/Tasman/Motueka/Shorelines/Motueka_19MAY1958.shp</td>\n",
       "      <td>Retrolens/Tasman/Motueka/Stack/Motueka_19MAY1958_mosaic.jp2</td>\n",
       "      <td>1.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Retrolens/Tasman/ TorrentBay/Shorelines/TorrentBay_09APR1965.shp</td>\n",
       "      <td>Retrolens/Tasman/ TorrentBay/Stack/TorrentBay_09APR1965_mosaic.jp2</td>\n",
       "      <td>0.763318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Retrolens/Tasman/ TorrentBay/Shorelines/TorrentBay_04MAY1944.shp</td>\n",
       "      <td>Retrolens/Tasman/ TorrentBay/Stack/TorrentBay_04MAY1944_mosaic.jp2</td>\n",
       "      <td>0.743579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1329</th>\n",
       "      <td>MaxarImagery/HighFreq/WestCoast/CartersBeach/Shorelines/CartersBeach_02MAR2019.shp</td>\n",
       "      <td>MaxarImagery/HighFreq/WestCoast/CartersBeach/Imagery/Stack/CartersBeach_02MAR2019.tif</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1330</th>\n",
       "      <td>MaxarImagery/HighFreq/WestCoast/Ohinemaka/Shorelines/Ohinemaka_25MAR2010.shp</td>\n",
       "      <td>MaxarImagery/HighFreq/WestCoast/Ohinemaka/Imagery/Stack/Ohinemaka_25MAR2010.tif</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>MaxarImagery/HighFreq/WestCoast/Ohinemaka/Shorelines/Ohinemaka_08MAR2022.shp</td>\n",
       "      <td>MaxarImagery/HighFreq/WestCoast/Ohinemaka/Imagery/Stack/Ohinemaka_08MAR2022.tif</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1338</th>\n",
       "      <td>MaxarImagery/HighFreq/Wellington/KapitiMid/Shorelines/KapitiMid_19JAN2006.shp</td>\n",
       "      <td>MaxarImagery/HighFreq/Wellington/KapitiMid/Imagery/Stack/KapitiMid_19JAN2006.tif</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>MaxarImagery/HighFreq/WestCoast/Hunt Beach/Shorelines/HuntBeach_30DEC2011.shp</td>\n",
       "      <td>MaxarImagery/HighFreq/WestCoast/Hunt Beach/Imagery/Stack/HuntBeach_30DEC2011.tif</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>441 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                filename  \\\n",
       "1                              Retrolens/Tasman/Motueka/Shorelines/Motueka_22SEP1969.shp   \n",
       "2                              Retrolens/Tasman/Motueka/Shorelines/Motueka_27MAR1947.shp   \n",
       "3                              Retrolens/Tasman/Motueka/Shorelines/Motueka_19MAY1958.shp   \n",
       "4                       Retrolens/Tasman/ TorrentBay/Shorelines/TorrentBay_09APR1965.shp   \n",
       "5                       Retrolens/Tasman/ TorrentBay/Shorelines/TorrentBay_04MAY1944.shp   \n",
       "...                                                                                  ...   \n",
       "1329  MaxarImagery/HighFreq/WestCoast/CartersBeach/Shorelines/CartersBeach_02MAR2019.shp   \n",
       "1330        MaxarImagery/HighFreq/WestCoast/Ohinemaka/Shorelines/Ohinemaka_25MAR2010.shp   \n",
       "1333        MaxarImagery/HighFreq/WestCoast/Ohinemaka/Shorelines/Ohinemaka_08MAR2022.shp   \n",
       "1338       MaxarImagery/HighFreq/Wellington/KapitiMid/Shorelines/KapitiMid_19JAN2006.shp   \n",
       "1346       MaxarImagery/HighFreq/WestCoast/Hunt Beach/Shorelines/HuntBeach_30DEC2011.shp   \n",
       "\n",
       "                                                                              matched_image  \\\n",
       "1                               Retrolens/Tasman/Motueka/Stack/Motueka_22SEP1969_mosaic.jp2   \n",
       "2                               Retrolens/Tasman/Motueka/Stack/Motueka_27MAR1947_mosaic.jp2   \n",
       "3                               Retrolens/Tasman/Motueka/Stack/Motueka_19MAY1958_mosaic.jp2   \n",
       "4                        Retrolens/Tasman/ TorrentBay/Stack/TorrentBay_09APR1965_mosaic.jp2   \n",
       "5                        Retrolens/Tasman/ TorrentBay/Stack/TorrentBay_04MAY1944_mosaic.jp2   \n",
       "...                                                                                     ...   \n",
       "1329  MaxarImagery/HighFreq/WestCoast/CartersBeach/Imagery/Stack/CartersBeach_02MAR2019.tif   \n",
       "1330        MaxarImagery/HighFreq/WestCoast/Ohinemaka/Imagery/Stack/Ohinemaka_25MAR2010.tif   \n",
       "1333        MaxarImagery/HighFreq/WestCoast/Ohinemaka/Imagery/Stack/Ohinemaka_08MAR2022.tif   \n",
       "1338       MaxarImagery/HighFreq/Wellington/KapitiMid/Imagery/Stack/KapitiMid_19JAN2006.tif   \n",
       "1346       MaxarImagery/HighFreq/WestCoast/Hunt Beach/Imagery/Stack/HuntBeach_30DEC2011.tif   \n",
       "\n",
       "      Pixel_ER  \n",
       "1     0.700000  \n",
       "2     0.550000  \n",
       "3     1.250000  \n",
       "4     0.763318  \n",
       "5     0.743579  \n",
       "...        ...  \n",
       "1329  0.500000  \n",
       "1330  0.500000  \n",
       "1333  0.500000  \n",
       "1338  0.600000  \n",
       "1346  0.500000  \n",
       "\n",
       "[441 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd  # Tabular data\n",
    "from glob import glob  # File pattern matching\n",
    "import os  # Operating System\n",
    "import geopandas as gpd  # Geospatial data\n",
    "import re  # Regular expressions\n",
    "import math\n",
    "from tqdm.auto import tqdm  # Progress bars\n",
    "from tqdm.contrib.concurrent import thread_map, process_map  # Parallel operations\n",
    "import rapidfuzz # Fuzzy string matching\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_colwidth\", 130)\n",
    "df = pd.read_csv(\"meta.csv\")\n",
    "# Filter to just shapefiles that have the CRS column defined\n",
    "df = df[df.CPS & (df.n_lines > 0)]\n",
    "df[\"Pixel_ER\"] = (\n",
    "    df.res.str.replace(\"(\", \"\", regex=False).str.split(\",\").str[0].astype(float)\n",
    ")\n",
    "df = df[[\"filename\", \"matched_image\", \"Pixel_ER\"]]\n",
    "# Testing with BigBay\n",
    "# df = df[df.filename.str.contains(\"BigBay\")]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total UNCY:  \n",
    "Total shoreline uncertainty (Et) is calculated as the root sum of squares of the pixel error (Ep), georeferencing error (Eg) and digitising error (Ed)  \n",
    "\n",
    "$E_t = \\sqrt{E_p^2 + E_g^2 + E_d^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c46e4dce481464d8ccfd891596dfafd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/441 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching 7/11/1952 to 17/11/1952 with score 94.73684210526316 for ressci201900060-RNC2-Coastal/Retrolens/Tasman/ TorrentBay/TorrentBay.csv\n",
      "Ambiguous scales found for ressci201900060-RNC2-Coastal/Retrolens/Tasman/RuataniwhaInlet/RuataniwhaInlet.csv for date 11/10/1950: Scale\n",
      "17400    6\n",
      "16700    1\n",
      "Name: count, dtype: int64. Taking 17400\n",
      "Matching 1980 to 30/01/1980 with score 90.0 for ressci201900060-RNC2-Coastal/Retrolens/Tasman/RuataniwhaInlet/RuataniwhaInlet.csv\n",
      "Retrolens/Tasman/Totaranui/Shorelines/Totaranui_09APR1965.shp has ambiguous DSASDates: ['09/04/1965' '9/04/1965']\n",
      "Retrolens/Tasman/Totaranui/Shorelines/Totaranui_08FEB1952.shp has ambiguous DSASDates: ['08/02/1952' '8/02/1952']\n",
      "Ambiguous CSVs: ['ressci201900060-RNC2-Coastal/Retrolens/Tasman/PortPuponga/PortPuponga.csv', 'ressci201900060-RNC2-Coastal/Retrolens/Tasman/PortPuponga/PortPuponga2.csv']\n",
      "Ambiguous CSVs: ['ressci201900060-RNC2-Coastal/Retrolens/Tasman/PortPuponga/PortPuponga.csv', 'ressci201900060-RNC2-Coastal/Retrolens/Tasman/PortPuponga/PortPuponga2.csv']\n",
      "Matching 18/09/1985 to 13/09/1985 with score 90.0 for ressci201900060-RNC2-Coastal/Retrolens/Tasman/MoutereSpit/MoutereSpit.csv\n",
      "Ambiguous CSVs: ['ressci201900060-RNC2-Coastal/Retrolens/Tasman/PortPuponga/PortPuponga.csv', 'ressci201900060-RNC2-Coastal/Retrolens/Tasman/PortPuponga/PortPuponga2.csv']\n",
      "Ambiguous CSVs: ['ressci201900060-RNC2-Coastal/Retrolens/Tasman/PortPuponga/PortPuponga.csv', 'ressci201900060-RNC2-Coastal/Retrolens/Tasman/PortPuponga/PortPuponga2.csv']\n",
      "Ambiguous CSVs: ['ressci201900060-RNC2-Coastal/Retrolens/Tasman/PortPuponga/PortPuponga.csv', 'ressci201900060-RNC2-Coastal/Retrolens/Tasman/PortPuponga/PortPuponga2.csv']\n",
      "Retrolens/Tasman/PoharaBeach/Shorelines/PoharaBeach_08FEB1952.shp has no sources\n",
      "Ambiguous CSVs: ['ressci201900060-RNC2-Coastal/Retrolens/Tasman/PortPuponga/PortPuponga.csv', 'ressci201900060-RNC2-Coastal/Retrolens/Tasman/PortPuponga/PortPuponga2.csv']\n",
      "Ambiguous CSVs: ['ressci201900060-RNC2-Coastal/Retrolens/Tasman/PortPuponga/PortPuponga.csv', 'ressci201900060-RNC2-Coastal/Retrolens/Tasman/PortPuponga/PortPuponga2.csv']\n",
      "Retrolens/Tasman/MoutereRiver/Shorelines/MoutereRiver_13SEP1985.shp has ambiguous sources: ['RL' None]\n",
      "Retrolens/Tasman/MoutereRiver/Shorelines/MoutereRiver_13SEP1985.shp has ambiguous DSASDates: ['13/09/1985' None]\n",
      "No scales found for ressci201900060-RNC2-Coastal/Retrolens/Tasman/MoutereRiver/MoutereRiver.csv for date 19/05/1958, removing RMSE filter\n",
      "Scales now: [44500]\n",
      "Retrolens/Southland/OretiBeach_West/Shorelines/OretiBeach_west_15FEB1976.shp has ambiguous DSASDates: ['15/02/1976' None]\n",
      "Matching 18/10/1985 to 18/10/1984 with score 90.0 for ressci201900060-RNC2-Coastal/Retrolens/Southland/OretiBeach_West/OretiBeach_West.csv\n",
      "ressci201900060-RNC2-Coastal/Retrolens/Manawatu/Akitio/Akitio.csv is actually an Excel file\n",
      "ressci201900060-RNC2-Coastal/Retrolens/Manawatu/Akitio/Akitio.csv is actually an Excel file\n",
      "Matching 21/10/1979 to 24/10/1979 with score 90.0 for ressci201900060-RNC2-Coastal/Retrolens/Auckland/MedlandsKaitoke/MedlandsKaitoke.csv\n",
      "Ambiguous scales found for ressci201900060-RNC2-Coastal/Retrolens/Auckland/MedlandsKaitoke/MedlandsKaitoke.csv for date 21/10/1979: Scale\n",
      "15000    3\n",
      "25000    1\n",
      "Name: count, dtype: int64. Taking 15000\n",
      "Matching 10/09/0971 to 10/9/1971 with score 84.21052631578947 for ressci201900060-RNC2-Coastal/Retrolens/Bay of Plenty/OmaioBay/OmaioBay.csv\n",
      "Matching 1/10/1980 to 01/10/1980 with score 94.73684210526316 for ressci201900060-RNC2-Coastal/Retrolens/Bay of Plenty/PapateaBay/PapateaBay.csv\n",
      "Matching 3/06/1939 to 03/06/1939 with score 94.73684210526316 for ressci201900060-RNC2-Coastal/Retrolens/Bay of Plenty/PapateaBay/PapateaBay.csv\n",
      "Matching 18/2/1988 to 18/02/1988 with score 94.73684210526316 for ressci201900060-RNC2-Coastal/Retrolens/WestCoast/GreymouthSouth/GreymouthSouth.csv\n",
      "Matching 21/5/1945 to 21/05/1945 with score 94.73684210526316 for ressci201900060-RNC2-Coastal/Retrolens/WestCoast/GreymouthSouth/GreymouthSouth.csv\n",
      "Matching 27/03/1943 to 27/05/1943 with score 90.0 for ressci201900060-RNC2-Coastal/Retrolens/WestCoast/Chesterfield/Chesterfield.csv\n",
      "Retrolens/WestCoast/HuntBeach/Shorelines/HuntBeach_14OCT1942.shp has ambiguous sources: ['RLN' None]\n",
      "Retrolens/WestCoast/HuntBeach/Shorelines/HuntBeach_14OCT1942.shp has ambiguous DSASDates: ['14/10/1942' None]\n",
      "Ambiguous scales found for ressci201900060-RNC2-Coastal/Retrolens/WestCoast/CartersBeach/CartersBeach.csv for date 13/03/1951: Scale\n",
      "15900    5\n",
      "8000     1\n",
      "Name: count, dtype: int64. Taking 15900\n",
      "Retrolens/Southland/HaldaneBay/Shorelines/HaldaneBay_07OCT1985.shp has ambiguous sources: ['RL' None]\n",
      "Retrolens/Southland/HaldaneBay/Shorelines/HaldaneBay_07OCT1985.shp has ambiguous DSASDates: ['07/10/1985' None]\n",
      "Matching 7/10/1985 to 17/10/1985 with score 94.73684210526316 for ressci201900060-RNC2-Coastal/Retrolens/Southland/HaldaneBay/HaldaneBay.csv\n",
      "MaxarImagery/HighFreq/Manawatu-Whanganui/Castlecliff/Shorelines/Castlecliff_10SEP2006.shp has no sources\n",
      "Matching 22/11/1969 to 22/09/1969 with score 80.0 for ressci201900060-RNC2-Coastal/Retrolens/Nelson/Nelson/Nelson.csv\n",
      "Retrolens/HawkesBay/TableCape/Shorelines/TableCape_18SEP1981.shp has no sources\n",
      "Retrolens/HawkesBay/TableCape/Shorelines/TableCape_18SEP1981.shp has no DSASDate\n",
      "Matching 1981 to 18/09/1981 with score 90.0 for ressci201900060-RNC2-Coastal/Retrolens/HawkesBay/TableCape/TableCape.csv\n",
      "Retrolens/Southland/WaipapaPoint/Shorelines/WaipapaPoint_15APR1948.shp has no sources\n",
      "Retrolens/Southland/WaipapaPoint/Shorelines/WaipapaPoint_15APR1948.shp has no DSASDate\n",
      "Matching 1948 to 15/04/1948 with score 90.0 for ressci201900060-RNC2-Coastal/Retrolens/Southland/WaipapaPoint/WaipapaPoint.csv\n",
      "Matching 18/10/1985 to 18/10/1984 with score 90.0 for ressci201900060-RNC2-Coastal/Retrolens/Southland/TeWaewaeBay_East1/TeWaewaeBay_East1.csv\n",
      "Retrolens/Southland/WaipapaPoint/Shorelines/WaipapaPoint_07OCT1985.shp has no DSASDate\n",
      "Matching 1985 to 17/10/1985 with score 90.0 for ressci201900060-RNC2-Coastal/Retrolens/Southland/WaipapaPoint/WaipapaPoint.csv\n",
      "Retrolens/Southland/WaipapaPoint/Shorelines/WaipapaPoint_21FEB1967.shp has no sources\n",
      "Retrolens/Southland/WaipapaPoint/Shorelines/WaipapaPoint_21FEB1967.shp has no DSASDate\n",
      "Matching 1967 to 21/02/1967 with score 90.0 for ressci201900060-RNC2-Coastal/Retrolens/Southland/WaipapaPoint/WaipapaPoint.csv\n",
      "Ambiguous scales found for ressci201900060-RNC2-Coastal/Retrolens/Southland/WaipapaPoint/WaipapaPoint.csv for date 25/02/1978: Scale\n",
      "27000    4\n",
      "49000    2\n",
      "Name: count, dtype: int64. Taking 27000\n",
      "Matching 17/03/1079 to 17/03/1979 with score 90.0 for ressci201900060-RNC2-Coastal/Retrolens/Southland/BigBay/BigBay.csv\n",
      "Retrolens/Southland/ColacBay/Shorelines/ColacBay_15FEB1952.shp has no Source\n",
      "No scales found for ressci201900060-RNC2-Coastal/Retrolens/Southland/CurioBay/CurioBay.csv for date 21/02/1967, removing RMSE filter\n",
      "Scales now: [67500]\n",
      "Retrolens/Southland/CosyNook/Shorelines/CosyNook_08OCT1985.shp has no sources\n",
      "Matching 8/10/1985 to 18/10/1984 with score 84.21052631578947 for ressci201900060-RNC2-Coastal/Retrolens/Southland/CosyNook/CosyNook.csv\n",
      "Matching 28/01/1998 to 28/11/1998 with score 90.0 for ressci201900060-RNC2-Coastal/Retrolens/Southland/OretiBeachSouth/OretiBeachSouth.csv\n",
      "MaxarImagery/HighFreq/WestCoast/GreymouthSouth/Shorelines/GreymouthSouth_23JUNE2019.shp doesn't have MAX source, overriding\n",
      "Matching 9/11/1981 to 9/09/1981 with score 77.77777777777779 for ressci201900060-RNC2-Coastal/Retrolens/HawkesBay/MohakaRiver_East/MohakaRiver_East.csv\n",
      "MaxarImagery/HighFreq/Wellington/KapitiMid/Shorelines/KapitiMid_31OCT2019.shp has ambiguous sources: ['MAX' None]\n"
     ]
    }
   ],
   "source": [
    "def get_scale(filename, DSASDate, year):\n",
    "    # Find CSV for AOI\n",
    "    bits = filename.split(\"/\")\n",
    "    terminator = min(\n",
    "        bits.index(\"Stack\") if \"Stack\" in bits else 1024,\n",
    "        bits.index(\"Shorelines\") if \"Shorelines\" in bits else 1024,\n",
    "    )\n",
    "    bits = bits[:terminator]\n",
    "    csv_path_pattern = f\"ressci201900060-RNC2-Coastal/{'/'.join(bits)}/*.csv\"\n",
    "    csv_candidates = glob(csv_path_pattern)\n",
    "    if len(csv_candidates) == 0:\n",
    "        print(f\"No CSV found for {csv_path_pattern}\")\n",
    "    elif len(csv_candidates) > 1:\n",
    "        print(f\"Ambiguous CSVs: {csv_candidates}\")\n",
    "        csv_candidates = [csv_candidates[0]]\n",
    "    assert len(csv_candidates) == 1\n",
    "    csv_filename = csv_candidates[0]\n",
    "    try:\n",
    "        csv = pd.read_csv(csv_filename, encoding=\"cp1252\")\n",
    "    except UnicodeDecodeError:\n",
    "        # Excel file saved with .csv extension\n",
    "        print(f\"{csv_filename} is actually an Excel file\")\n",
    "        csv = pd.read_excel(csv_filename)\n",
    "        csv.Date = csv.Date.astype(str)\n",
    "    if \"RMSE\" not in csv.columns:\n",
    "        print(f\"{csv_filename} has no RMSE column\")\n",
    "    \n",
    "\n",
    "    # Fuzzy string match dates. Lots of typos.\n",
    "    matched_date, score, index = rapidfuzz.process.extractOne(query=DSASDate, choices=csv.Date.unique())\n",
    "    if score < 50:\n",
    "        # Terrible match score, just use year\n",
    "        matched_date, score, index = rapidfuzz.process.extractOne(query=year, choices=csv.Date.unique())\n",
    "        print(f\"Matching {year} to {matched_date} with score {score} for {csv_filename}\")\n",
    "    elif DSASDate != matched_date:\n",
    "        print(f\"Matching {DSASDate} to {matched_date} with score {score} for {csv_filename}\")\n",
    "    filtered_csv = csv[(csv.Date == matched_date) & ~csv.RMSE.isna()]\n",
    "    scales = filtered_csv.Scale.unique()\n",
    "    if len(scales) == 0:\n",
    "        print(f\"No scales found for {csv_filename} for date {DSASDate}, removing RMSE filter\")\n",
    "        filtered_csv = csv[(csv.Date.str.contains(matched_date))]\n",
    "        scales = filtered_csv.Scale.unique()\n",
    "        print(f\"Scales now: {scales}\")\n",
    "        if len(scales) == 0:\n",
    "            print(f\"Still no scales found for {csv_filename} for date {matched_date}, reducing date filter just to year from filename {year}\")\n",
    "            filtered_csv = csv[(csv.Date.str.contains(year))]\n",
    "            scales = filtered_csv.Scale.unique()\n",
    "            print(f\"Scales now: {scales}\")\n",
    "    if len(scales) > 1:\n",
    "        scales = filtered_csv.Scale.value_counts()\n",
    "        print(f\"Ambiguous scales found for {csv_candidates[0]} for date {DSASDate}: {scales}. Taking {scales.index[0]}\")\n",
    "        scales = [scales.index[0]]\n",
    "    if len(scales) == 0:\n",
    "        print(f\"Can't find a scale for {filename}\")\n",
    "    assert len(scales) == 1\n",
    "    return scales[0]\n",
    "\n",
    "\n",
    "def get_Georef_ER(scale):\n",
    "    if scale < 20000:\n",
    "        return 2.09\n",
    "    elif scale < 30000:\n",
    "        return 2.43\n",
    "    else:\n",
    "        return 2.9\n",
    "\n",
    "\n",
    "CPS_error_lookup = {1: 0.43, 2: 0.73, 3: 0.97, 4: 2.07, 5: 8.59}\n",
    "\n",
    "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    filename = row.filename\n",
    "    year = re.search(r'(\\d{4})', filename).group(1)\n",
    "    shapefile = gpd.read_file(filename)\n",
    "    if len(shapefile) == 0:\n",
    "        print(f\"{filename} is empty\")\n",
    "        continue\n",
    "    if \"Source\" not in shapefile.columns:\n",
    "        print(f\"{filename} has no Source\")\n",
    "        if filename.startswith(\"Retrolens\"):\n",
    "            source = \"RL\"\n",
    "        elif filename.startswith(\"MaxarImagery/HighFreq\"):\n",
    "            source = \"MAX\"\n",
    "        else:\n",
    "            source = \"Unknown\"\n",
    "    else:\n",
    "        sources = shapefile.Source.unique()\n",
    "        if len(sources) == 0 or not sources[0]:\n",
    "            print(f\"{filename} has no sources\")\n",
    "            if filename.startswith(\"MaxarImagery/HighFreq\"):\n",
    "                sources = [\"MAX\"]\n",
    "            else:\n",
    "                sources = [\"Unknown\"]\n",
    "        if len(sources) > 1:\n",
    "            print(f\"{filename} has ambiguous sources: {sources}\")\n",
    "        source = sources[0]\n",
    "\n",
    "    if source != \"MAX\" and filename.startswith(\"MaxarImagery\"):\n",
    "        print(f\"{filename} doesn't have MAX source, overriding\")\n",
    "        source = \"MAX\"\n",
    "\n",
    "    if source == \"MAX\":\n",
    "        photoscale = \"VHR\"\n",
    "        Georef_ER = 1.17\n",
    "    elif source == \"LDS\":\n",
    "        photoscale = \"VHR\"\n",
    "        Georef_ER = 0\n",
    "    else:\n",
    "        dates = shapefile.DSASDate.unique()\n",
    "        if len(dates) > 1:\n",
    "            print(f\"{filename} has ambiguous DSASDates: {dates}\")\n",
    "        if len(dates) == 0 or not dates[0]:\n",
    "            print(f\"{filename} has no DSASDate\")\n",
    "            DSASDate = year\n",
    "        else:\n",
    "            DSASDate = shapefile.DSASDate.unique()[0].lstrip(\"0\")\n",
    "        photoscale = get_scale(filename, DSASDate, year)\n",
    "        Georef_ER = get_Georef_ER(photoscale)\n",
    "\n",
    "    # Store inputs in shapefile\n",
    "    shapefile[\"Photoscale\"] = photoscale\n",
    "    shapefile[\"Georef_ER\"] = Georef_ER\n",
    "    shapefile[\"Pixel_Er\"] = row.Pixel_ER\n",
    "\n",
    "    # Calculate Total_UNCY\n",
    "    Ep = row.Pixel_ER\n",
    "    Eg = Georef_ER\n",
    "    for i, row in shapefile.iterrows():\n",
    "        if row.CPS not in CPS_error_lookup:\n",
    "            continue\n",
    "        Ed = CPS_error_lookup[row.CPS]\n",
    "        Et = math.sqrt(Ep**2 + Eg**2 + Ed**2)\n",
    "        shapefile.loc[i, \"Total_UNCY\"] = Et\n",
    "    # display(shapefile)\n",
    "    # To write results back to file:\n",
    "    shapefile.to_file(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
